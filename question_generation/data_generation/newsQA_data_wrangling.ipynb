{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import pickle\n",
    "import importlib\n",
    "import random\n",
    "import re\n",
    "\n",
    "import data_utils\n",
    "importlib.reload(data_utils)\n",
    "\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "pandas.set_option('display.max_rows', 500)\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NewsQA dataset with annotated answers in paragraphs and answer sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function that returns tokenized data with answer annotations in paragraphs/answer sentences'''\n",
    "\n",
    "\n",
    "def make_newsqa_qg_dataset(data):\n",
    "    wrangled_data = {'article_id': [],\n",
    "                     'paragraph': [],\n",
    "                     'answer_sent': [],\n",
    "                     'question': [],\n",
    "                     'answer': [],\n",
    "                     }\n",
    "#     import pdb\n",
    "#     pdb.set_trace()\n",
    "    for article_idx, article in enumerate(data):\n",
    "        #         for paragraph in article['paragraphs']:\n",
    "        paragraph = article['text']\n",
    "        paragraph_sents = data_utils.segment_sents(paragraph)\n",
    "        for qa in article['questions']:\n",
    "            question_text = qa['q']\n",
    "            try:\n",
    "                answer_char_start = qa['consensus']['s']\n",
    "                answer_char_end = qa['consensus']['e']\n",
    "            except:\n",
    "                #No answer to this question\n",
    "#                 import pdb;pdb.set_trace()\n",
    "                continue\n",
    "            #Ensure first character in question is capitalized and question ends with question mark\n",
    "            if question_text[0].islower():\n",
    "                question_text = question_text[0].upper() + question_text[1:]\n",
    "            if question_text[-1] != \"?\":\n",
    "                question_text += \"?\"\n",
    "            answer_text = re.sub(\"\\n+\", \" \", paragraph[answer_char_start:answer_char_end].strip())\n",
    "            for sent_idx in range(len(paragraph_sents['sents'])):\n",
    "                sent_char_start = paragraph_sents['sent_char_start_idxs'][sent_idx]\n",
    "                if sent_idx + 1 == len(paragraph_sents['sents']):\n",
    "                    #import pdb;pdb.set_trace()\n",
    "                    sent_char_end = (paragraph_sents['sent_char_start_idxs'][-1] +\n",
    "                                     len(paragraph_sents['sents'][-1]))\n",
    "                    if sent_char_end != len(paragraph):\n",
    "                        import pdb\n",
    "                        pdb.set_trace()\n",
    "                else:\n",
    "                    sent_char_end = paragraph_sents['sent_char_start_idxs'][sent_idx + 1]\n",
    "                if sent_char_start <= answer_char_start < sent_char_end:\n",
    "                    while answer_char_end > sent_char_end:\n",
    "                        # Answer spans multiple sentences, which is probably a segmentation failure;\n",
    "                        # just append next sentence to this one as answer sentence\n",
    "                        try:\n",
    "                            #                                     import pdb;pdb.set_trace()\n",
    "                            paragraph_sents['sents'][sent_idx] = (paragraph_sents['sents'][sent_idx] +\n",
    "                                                                  paragraph_sents['sents'][sent_idx + 1])\n",
    "                            paragraph_sents['sents'].pop(sent_idx + 1)\n",
    "                            paragraph_sents['sent_char_start_idxs'].pop(\n",
    "                                sent_idx + 1)\n",
    "                            if sent_idx + 1 == len(paragraph_sents['sents']):\n",
    "                                sent_char_end = len(paragraph)\n",
    "                            else:\n",
    "                                sent_char_end = paragraph_sents['sent_char_start_idxs'][sent_idx + 1]\n",
    "                        except:\n",
    "                            import pdb\n",
    "                            pdb.set_trace()\n",
    "                    answer_sent_text = paragraph_sents['sents'][sent_idx]\n",
    "                    # insert answer tokens into sentence\n",
    "                    answer_start_insert_idx = answer_char_start - sent_char_start\n",
    "                    answer_end_insert_idx = answer_char_end - sent_char_start\n",
    "                    answer_sent_text = (answer_sent_text[:answer_start_insert_idx] + \"<ANSWER> \"\n",
    "                                        + answer_sent_text[answer_start_insert_idx:])\n",
    "                    answer_sent_text = (answer_sent_text[:answer_end_insert_idx + len(\"<ANSWER> \")]\n",
    "                                        + \"</ANSWER> \" +\n",
    "                                        answer_sent_text[answer_end_insert_idx + len(\" <ANSWER>\"):])\n",
    "                    answer_sent_text = re.sub(\"\\n+\", \" \", answer_sent_text.strip())\n",
    "                    paragraph_sents_with_answer = paragraph_sents['sents'][:]\n",
    "                    paragraph_sents_with_answer[sent_idx] = answer_sent_text\n",
    "                    paragraph_text = \" \".join([re.sub(\"\\n+\", \" \", sent.strip()) \n",
    "                                               for sent in paragraph_sents_with_answer])\n",
    "                    break\n",
    "            wrangled_data['article_id'].append(article_idx)\n",
    "            wrangled_data['paragraph'].append(paragraph_text) \n",
    "            wrangled_data['answer_sent'].append(answer_sent_text)\n",
    "            wrangled_data['question'].append(question_text.strip())\n",
    "            wrangled_data['answer'].append(answer_text)\n",
    "            #print(\"paragraph done\")\n",
    "        if article_idx and article_idx % 50 == 0:\n",
    "            print(article_idx)\n",
    "#             break\n",
    "    return wrangled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load pre-processed NewsQA dataset'''\n",
    "\n",
    "newsqa_data_dir = \"/home/mroemmele/news_QA/\"\n",
    "partition = 'test'\n",
    "assert partition in ('train', 'test')\n",
    "data = pickle.load(open(os.path.join(newsqa_data_dir, \n",
    "                                     '{}_data.pkl'.format('dev' if partition == 'test' else partition)), 'rb'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-4-5723da3fbaa7>(21)make_newsqa_qg_dataset()\n",
      "-> answer_char_start = qa['consensus']['s']\n",
      "(Pdb) qa\n",
      "{'isQuestionBad': 0.0, 'q': 'Iran criticizes who?', 'validatedAnswers': [{'count': 2, 's': 63, 'e': 97}], 'answers': [{'sourcerAnswers': [{'s': 68, 'e': 97}]}, {'sourcerAnswers': [{'s': 63, 'e': 97}]}, {'sourcerAnswers': [{'noAnswer': True}]}], 'consensus': {'s': 63, 'e': 97}, 'isAnswerAbsent': 0.33333333333299997}\n",
      "(Pdb) c\n",
      "> <ipython-input-4-5723da3fbaa7>(20)make_newsqa_qg_dataset()\n",
      "-> import pdb;pdb.set_trace()\n",
      "(Pdb) n\n",
      "> <ipython-input-4-5723da3fbaa7>(21)make_newsqa_qg_dataset()\n",
      "-> answer_char_start = qa['consensus']['s']\n",
      "(Pdb) qa\n",
      "{'isQuestionBad': 0.0, 'q': 'What are US and Iran relations tensioned about?', 'validatedAnswers': [{'count': 2, 's': 2558, 'e': 2575}], 'answers': [{'sourcerAnswers': [{'noAnswer': True}]}, {'sourcerAnswers': [{'s': 2558, 'e': 2575}]}, {'sourcerAnswers': [{'s': 120, 'e': 169}]}], 'consensus': {'s': 2558, 'e': 2575}, 'isAnswerAbsent': 0.33333333333299997}\n",
      "(Pdb) c\n",
      "> <ipython-input-4-5723da3fbaa7>(20)make_newsqa_qg_dataset()\n",
      "-> import pdb;pdb.set_trace()\n",
      "(Pdb) qa\n",
      "{'q': 'Who said Obama should apply campaign message?', 'isQuestionBad': 0.0, 'consensus': {'s': 267, 'e': 280}, 'answers': [{'sourcerAnswers': [{'s': 267, 'e': 280}]}, {'sourcerAnswers': [{'s': 267, 'e': 280}]}, {'sourcerAnswers': [{'s': 267, 'e': 280}]}], 'isAnswerAbsent': 0.0}\n",
      "(Pdb) c\n",
      "> <ipython-input-4-5723da3fbaa7>(21)make_newsqa_qg_dataset()\n",
      "-> answer_char_start = qa['consensus']['s']\n",
      "(Pdb) qa\n",
      "{'isQuestionBad': 0.0, 'q': 'What should Obama apply according to speaker?', 'validatedAnswers': [{'count': 1, 'noAnswer': True}, {'count': 2, 's': 318, 'e': 349}], 'answers': [{'sourcerAnswers': [{'noAnswer': True}]}, {'sourcerAnswers': [{'s': 267, 'e': 280}]}, {'sourcerAnswers': [{'s': 318, 'e': 349}, {'s': 352, 'e': 377}]}], 'consensus': {'s': 318, 'e': 349}, 'isAnswerAbsent': 0.33333333333299997}\n",
      "(Pdb) q\n",
      "> <ipython-input-4-5723da3fbaa7>(20)make_newsqa_qg_dataset()\n",
      "-> import pdb;pdb.set_trace()\n",
      "(Pdb) q\n",
      "> <ipython-input-4-5723da3fbaa7>(21)make_newsqa_qg_dataset()\n",
      "-> answer_char_start = qa['consensus']['s']\n",
      "(Pdb) q\n",
      "> <ipython-input-4-5723da3fbaa7>(20)make_newsqa_qg_dataset()\n",
      "-> import pdb;pdb.set_trace()\n",
      "(Pdb) q\n",
      "> <ipython-input-4-5723da3fbaa7>(21)make_newsqa_qg_dataset()\n",
      "-> answer_char_start = qa['consensus']['s']\n",
      "(Pdb) q\n",
      "> <ipython-input-4-5723da3fbaa7>(20)make_newsqa_qg_dataset()\n",
      "-> import pdb;pdb.set_trace()\n",
      "(Pdb) q\n",
      "> <ipython-input-4-5723da3fbaa7>(21)make_newsqa_qg_dataset()\n",
      "-> answer_char_start = qa['consensus']['s']\n",
      "(Pdb) qa\n",
      "{'q': 'What kind of weapons are being discussed?', 'isQuestionBad': 0.0, 'consensus': {'s': 137, 'e': 145}, 'answers': [{'sourcerAnswers': [{'s': 137, 'e': 145}]}, {'sourcerAnswers': [{'s': 137, 'e': 145}]}, {'sourcerAnswers': [{'s': 137, 'e': 145}]}], 'isAnswerAbsent': 0.0}\n",
      "(Pdb) q\n",
      "> <ipython-input-4-5723da3fbaa7>(20)make_newsqa_qg_dataset()\n",
      "-> import pdb;pdb.set_trace()\n",
      "(Pdb) q\n",
      "> <ipython-input-4-5723da3fbaa7>(21)make_newsqa_qg_dataset()\n",
      "-> answer_char_start = qa['consensus']['s']\n",
      "(Pdb) q\n",
      "> <ipython-input-4-5723da3fbaa7>(20)make_newsqa_qg_dataset()\n",
      "-> import pdb;pdb.set_trace()\n",
      "(Pdb) import sys\n",
      "(Pdb) sys._exit()\n",
      "*** AttributeError: module 'sys' has no attribute '_exit'\n",
      "(Pdb) q\n"
     ]
    }
   ],
   "source": [
    "'''Make the dataset'''\n",
    "\n",
    "wrangled_data = make_newsqa_qg_dataset(data)\n",
    "pandas.DataFrame(wrangled_data)[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Save the dataset'''\n",
    "\n",
    "data_dir = \"/home/mroemmele/question_generation/newsqa_untok_data\"\n",
    "\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "if not os.path.isdir(os.path.join(data_dir, partition)):\n",
    "    os.mkdir(os.path.join(data_dir, partition))\n",
    "       \n",
    "with open(os.path.join(data_dir, partition, 'paragraphs.txt'), 'w') as f:\n",
    "    f.write(\"\\n\".join(wrangled_data['paragraph']))\n",
    "    \n",
    "with open(os.path.join(data_dir, partition, 'answer_sents.txt'), 'w') as f:\n",
    "    f.write(\"\\n\".join(wrangled_data['answer_sent']))\n",
    "\n",
    "with open(os.path.join(data_dir, partition, 'questions.txt'), 'w') as f:\n",
    "    f.write(\"\\n\".join(wrangled_data['question']))\n",
    "    \n",
    "with open(os.path.join(data_dir, partition, 'answers_only.txt'), 'w') as f:\n",
    "    f.write(\"\\n\".join(wrangled_data['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
